cat(named.text.word.vector.1[[file.id]][start:hits.v[h] - length(hits.v)] , "[", keyword, "]", hits.v[h] + length(paste("[", keyword, "]")):end,"\n")
}
}
}
doitKwic(mycorpus.l)
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[file.id][start:(start + context -1)]
after<-named.text.word.vector.1[file.id][(start+context+1)]
keyword = named.text.word.vector.1[file.id][start+context]
cat(before, "[", keyword, "]", after,"\n")
}
}
}
doitKwic(mycorpus.l)
debugSource('C:/Users/Bill/OneDrive - usafa.edu/211Z/CloseReadingEssay2Materials/TextAnalysisWithR/code/show.files.R')
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[file.id][start:(start + context -1)]
after<-named.text.word.vector.1[file.id][(start+context+1)]
keyword = named.text.word.vector.1[file.id][start+context]
cat(before, "[", keyword, "]", after,"\n")
}
}
}
doitKwic(mycorpus.l)
debugSource('C:/Users/Bill/OneDrive - usafa.edu/211Z/CloseReadingEssay2Materials/TextAnalysisWithR/code/show.files.R')
View(doitKwic)
View(doitKwic)
View(doitKwic)
View(doitKwic)
View(doitKwic)
View(doitKwic)
View(doitKwic)
debugSource('C:/Users/Bill/OneDrive - usafa.edu/211Z/CloseReadingEssay2Materials/TextAnalysisWithR/code/show.files.R')
doitKwic(mycorpus.l)
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[file.id][start:(start + context -1)]
after<-named.text.word.vector.1[file.id][(start+context+1)]
keyword = named.text.word.vector.1[file.id][start+context]
cat("[", keyword, "]", after,"\n")
}
}
}
doitKwic(mycorpus.l)
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[file.id][start:(start + context -1)]
after<-named.text.word.vector.1[file.id][(start+context+1) :end]
keyword = named.text.word.vector.1[file.id][start+context]
cat("[", keyword, "]", after,"\n")
}
}
}
doitKwic(mycorpus.l)
files.v
files.v[1]
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[file.id][start:(start + context -1)]
after<-named.text.word.vector.1[file.id][(start+context+1) :end]
keyword = named.text.word.vector.1[file.id][start+context]
cat("[", keyword, "]", after,"\n")
}
}
}mycorpus.l
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[file.id][start:(start + context -1)]
after<-named.text.word.vector.1[file.id][(start+context+1) :end]
keyword = named.text.word.vector.1[file.id][start+context]
cat("[", keyword, "]", after,"\n")
}
}
}mycorpus.l
mycorpus.l
mycorpus.l[1]
source('C:/Users/Bill/OneDrive - usafa.edu/211Z/CloseReadingEssay2Materials/TextAnalysisWithR/code/show.files.R')
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[file.id][start:(start + context -1)]
after<-named.text.word.vector.1[file.id][(start+context+1) :end]
keyword = named.text.word.vector.1[file.id][start+context]
cat("[", keyword, "]", after,"\n")
}
}
}
doitKwic(mycorpus.l)
hits.v <- which(mycorpus.l[1] == "creature")
hist.v
hits.v
hits.v
hits.v <- which(mycorpus.l[[1]] == "creature")
hits.v
ls(start())
typeof(start())
start < hits.v[1]
hits.v[1]
start <- hits.v[1]
start
before <- mycorpus.l
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[[file.id]][start:(start + context -1)]
after<-named.text.word.vector.1[[file.id]][(start+context+1) :end]
keyword = named.text.word.vector.1[[file.id]][start+context]
cat("[", keyword, "]", after,"\n")
}
}
}
doitKwic(mycorpus.l)
doitKwic <- function(named.text.word.vector.1){
show.files(names(named.text.word.vector.1))
file.id <- as.numeric(readline("Enter file number: \n"))
context <- as.numeric(readline("Enter context size: \n"))
keyword <- tolower(readline("Enter keyword: \n"))
hits.v <- which(named.text.word.vector.1[[file.id]] == keyword)
if(length(hits.v) >0){
for(h in 1:length(hits.v)){
start <- hits.v[h] - context
if(start <1){
start <--1
}
end <-hits.v[h]+context
before<-named.text.word.vector.1[[file.id]][start:(start + context -1)]
after<-named.text.word.vector.1[[file.id]][(start+context+1) :end]
keyword = named.text.word.vector.1[[file.id]][start+context]
cat(before, "[", keyword, "]", after,"\n")
}
}
}
doitKwic(mycorpus.l)
doitKwic(mycorpus.l)
install.packages("XML")
library(XML)
load("C:/Users/Bill/OneDrive - usafa.edu/211Z/CloseReadingEssay2Materials/TextAnalysisWithR/.RData")
mycorpus.l[1]
mycorpus.l[[1]]
myvector.l <-list()
myvector.l
myvector.l <- mycorpus.l
myvector.l
myvector.l[1]
myvector.l[12]
myvector.l[2]
myvector.l[[2]]
myvector.l["data/plainText/franenstein-1818.txt"]
myvector.l[["data/plainText/franenstein-1818.txt"]]
myvector.l
myvector.l[["data/plainText/franenstein-1818.txt"]]
myvector.l[["franenstein-1818.txt"]]
myvector.l[["data/plainText/frankenstein-1818.txt"]]
myvector.l["data/plainText/frankenstein-1818.txt"]
myvector.l[["frankenstein-1818.txt"]]
myvector.l[["frankenstein-1818.txt"]][1]
myvector.l["frankenstein-1818.txt"][1]
myvector.l["frankenstein-1818.txt"]
text.v <-scan("data/plainText/Frankenstein/frankenstein-1818.txt")
text.v <-scan("data/plainText/Frankenstein/frankenstein-1818.txt", what="character")
text.v
text.v <-scan("data/plainText/Frankenstein/frankenstein-1818.txt", sep="/", what="character")
text.v
text.v <-scan("data/plainText/Frankenstein/frankenstein-1818.txt", what="character", sep="\n")
text.v
text.v
text.v <- paste(text.v, collapse = " ")
text.v
text.lower.v <- tolower(text.v)
text.v
text.tolower.v
text.lower.v
text.words.v <- strsplit(text.lower.v, "\\W")
text.words.v
text.words.v <- unlist(text.words.v)
text.words.v
typeof(text.v)
class(text.v)
attributes(text.v)
is.list(text.v)
is.vector(text.v)
is.matrix(text.v)
text.words.v <- text.words.v[which(text.words.v !="")
text.words.v <- text.words.v[which(text.words.v !="")]
text.words.v
files.v[1]
files.v[[1]]
text.word.vector.l[[files.v[1]]] <- text.words.v
text.word.vector.l[files.v[1]] <- text.words.v
text.word.vector.l <- list()
text.word.vector.l[[files.v[1]]] <- text.words.v
text.word.vector.l
is.list(text.word.vector.l)
is.vector(text.words.v)
load("code/corpusFunctions.R")
source("code/corpusFunctions.R")
source("code/corpusFunctions.R")
source("code/corpusFunctions.R")
files.v
input.dir
View(doitKwic)
View(doitKwic)
View(doitKwic)
View(doitKwic)
View(show.files)
View(make.file.word.v.l)
View(doitKwic)
View(doitKwic)
View(make.file.word.v.l)
View(make.file.word.v.l)
View(show.files)
typeof(input.dir)
class(input.dir)
input.dir
dirname(rstudioapi::getSourceEditorContext()$path)
source()
installed.packages()
.libPaths()
diffr(f1,f2,before = files.v[1], after = files.v[2])
install.packages("diffr")
library(diffr)
diffr(f1,f2,before = files.v[1], after = files.v[2])
diffr(f1,f2,before = files.v[1], after = files.v[2])
diffr(f1,f2,before = files.v[1], after = files.v[2])
library()
library(diffr)
install.packages('diffr')
library(diffr)
ms_txt<-"data/plainText/RedBadg/rboc-ms.txt"
ms_txt
appleton<-"data/plainText/RedBadge/appleton.txt"
ms_txt<-"data/plainText/RedBadge/rboc-ms.txt"
appleton
diff(ms_txt,appleton)
diffr(ms_txt,appleton)
diffr(ms_txt,appleton)
ms_txt
diffr(ms_txt, appleton.txt)
librar(diffr)
library(diffr)
ms_text
ms_txt
appleton_txt
appleton
diffr(ms_txt,appleton)
diffr(ms_txt,appleton)
diffr(ms_txt,appleton)
diffr(ms_txt,appleton)
library(XML)
install.packages("XM")
install.packages("XML")
library(XML)
doc <- xmlTreeParse("blackriders.xml", useInternalNodes=TRUE)
doc <- xmlTreeParse("blackriders.xml", useInternalNodes=TRUE)
doc <- xmlTreeParse("blackriders.xml", useInternalNodes=TRUE)
divs.ns.l <- getNodeSet(doc, "/tei:TEI//tei:*[@ana='#ref-object']", namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
words.v <- paste(sapply(divs.ns.l, xmlValue))
words.v
divs.ns.l <- getNodeSet(doc, "/tei:TEI//tei:*[@ana='#ref-object']", namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
words.v <- paste(sapply(divs.ns.l, xmlValue))
words.v
divs.ns.l <- getNodeSet(doc, "/tei:TEI//tei:*[@ana='#ref-human']", namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
words.v <- paste(sapply(divs.ns.l, xmlValue))
words.v
words.v
words.v
divs.ns.l <- getNodeSet(doc, "/tei:TEI//tei:*[@ana='#ref-animal']", namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
library(XML)
doc <- xmlTreeParse("blackriders.xml", useInternalNodes=TRUE)
divs.ns.l <- getNodeSet(doc, "/tei:TEI//tei:*[@ana='#ref-animal']", namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
words.v <- paste(sapply(divs.ns.l, xmlValue))
words.v
library(XML)
doc <- xmlTreeParse("blackriders.xml", useInternalNodes=TRUE)
divs.ns.l <- getNodeSet(doc, "/tei:TEI//tei:*[@ana='#ref-deity']", namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
words.v <- paste(sapply(divs.ns.l, xmlValue))
words.v
doc <- xmlTreeParse("blackriders.xml", useInternalNodes=TRUE)
divs.ns.l <- getNodeSet(doc, "/tei:TEI//tei:*[@ana='#ref-object']", namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
words.v <- paste(sapply(divs.ns.l, xmlValue))
words.v
doc <- xmlTreeParse("blackriders.xml", useInternalNodes=TRUE)
divs.ns.l <- getNodeSet(doc, "/tei:TEI//tei:*[@ana='#ref-deity']", namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
words.v <- paste(sapply(divs.ns.l, xmlValue))
words.v
load("C:/Users/Bill/OneDrive - usafa.edu/TidyTextMining/.RData")
install.packages(c("e1071", "caret", "quanteda", "irlba", "randomForest"))
getwd()
text
?names
typeof(text)
text.v < data.frame(text)
text.v <- data.frame(text)
text.v
View(text.v)
view(text)
setwd("C:/Users/Bill/OneDrive - usafa.edu/Rprojects/Marginalia/text")
library(c("ggplot2", "e1071", "caret", "quanteda",
"irlba", "randomForest"))
install.packages(c("ggplot2", "e1071", "caret", "quanteda",
"irlba", "randomForest"))
library(c("ggplot2", "e1071", "caret", "quanteda",
"irlba", "randomForest"))
library(ggplot2)
library(e1071)
library("randomForest", lib.loc="~/R/win-library/3.6")
library("irlba", lib.loc="~/R/win-library/3.6")
install.packages("e1071")
library("e1071", lib.loc="~/R/win-library/3.6")
install.packages("caret")
library("caret", lib.loc="~/R/win-library/3.6")
install.packages("quanteda")
library("quanteda", lib.loc="~/R/win-library/3.6")
library("randomForest", lib.loc="~/R/win-library/3.6")
library("ggplot2", lib.loc="~/R/win-library/3.6")
library("irlba", lib.loc="~/R/win-library/3.6")
library("caret", lib.loc="~/R/win-library/3.6")
library("e1071", lib.loc="~/R/win-library/3.6")
mbtxt <- readLines("moby-dick_gutenberglbremoved.txt")
mbtxt
View(mbtxt)
text_df
text_df <- data.frame(mbtxt)
text_df
View(text_df)
typeof(text_df)
length(which(!complete.cases(text_df)))
prop.table(table(text_df))
summary(text_df)
?tokens
text_df.tokens <- tokens(text_df, what = "word",
remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_hyphens = TRUE)
mbtxt.tokens <- tokens(mbtxt, what = "word",
remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_hyphens = TRUE
typeof(mbtxt)
typeof("mbtxt")
typeof(mbtxt)
mbtxt.tokens <- tokens(mbtxt, what = "word",
remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_hyphens = TRUE)
mbtxt.tokens
mbtxt.tokens.lower <- tolower(mbtxt.tokens)
mbtxt.tokens.lower
?stopwords
mbtxt.tokens.lower <- tokens_select(mbtxt.tokens.lower, stopwords(), selection = "remove")
?tokens_select
mbtxt.tokens.lower <- tokens_select(mbtxt.tokens.lower, stopwords(), selection = "remove")
mbtxt.tokens <- tokens_select(mbtxt.tokens, stopwords(), selection = "remove")
getwd()
setwd("C:/Users/Bill/OneDrive - usafa.edu/Rprojects/Marginalia")
mbtxt.tokens <- tokens_select(mbtxt.tokens, stopwords(), selection = "remove")
stopwords()
stop_words
mbtxt.tokens <- tokens_select(mbtxt.tokens, stop_words, selection = "remove")
mbtxt.tokens
mbtxt.tokens <- tolower(mbtxt.tokens)
mbtxt
View(mbtxt.tokens)
text.df <- tolower(text.df)
text_df <- tolower(text_df)
view(text_df)
mbtxt <- tolower(mbtxt)
View(mbtxt)
mbtxt[577]
mbtxt[576]
mbtxt.tokens <- tokens(mbtxt, what = "word",
remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_hyphens = TRUE)
mbtxt.tokens
mbtxt.tokens[2690]
typof(mbtxt.tokens)
typeof(mbtxt.tokens)
install.packages("rlist")
library(rlist)
list.clean(mbtxt.tokens)
list.clean(mbtxt)
View(mbtxt)
library(rlist)
x <- list(a=NULL,b=list(x=NULL,y=character()),d=1,e=2)
x
list.clean(mbtxt, function(x) length(x) == 0L, TRUE)
mbtxt[19]
?write
write(mbtxt, file = "mbtxt.txt", ncolumns = 1)
mbtxt.raw <- read.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-16")
mbtxt.raw <- read.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-16")
View(mbtxt.raw)
mbtxt.raw <- read.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-8")
?read.csv
mbtxt.raw <- read.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-16")
mbtxt.raw <- read.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-8")
mbtxt.raw <- read.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-8")
mbtxt.raw <- read2.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-8")
mbtxt.raw <- read2.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-8")
mbtxt.raw <- read.csv2("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-8")
?read.table
mbtxt.raw <- read.csv("mbtxt.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-8", fill = TRUE)
mbtxt.raw <- read.csv("mbtxt.csv", sep = ",", stringsAsFactors = FALSE, fileEncoding = "UTF-8", fill = TRUE)
?data.frame
setwd("C:/Users/Bill/OneDrive - usafa.edu/Rprojects/Marginalia")
load("C:/Users/Bill/OneDrive - usafa.edu/Rprojects/Marginalia/.RData")
View(mbtxt.tokens)
stopwords()
remove.packages("quanteda", lib="~/R/win-library/3.6")
install.packages('quanteda')
install.packages("quanteda")
load(quanteda)
install.packages("quanteda")
load(quanteda)
library("quanteda", lib.loc="~/R/win-library/3.6")
stopwords()
load(quanteda)
library(quanteda)
stopwords()
original_books
stop_words
ms_txt
mvtxt.df
mstxt.df
mbtxt.df
mbtxt.raw
mbtxt.tokens
